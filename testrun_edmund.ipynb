{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ded87-b9ba-49f5-8b96-5d9835158d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# After installation, restart your kernel, then run:\n",
    "import torch\n",
    "print(torch.cuda.is_available())   \n",
    "print(torch.cuda.get_device_name(0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909e826-be92-41e3-8310-0d5ca1e92a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imgaug\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from dataset import dataset\n",
    "from UNetModela import UNet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set paths\n",
    "image_dir = r\"C:\\Users\\edmun\\Downloads\\forintern\\dataset\\images\"\n",
    "mask_dir = r\"C:\\Users\\edmun\\Downloads\\forintern\\dataset\\masks\"\n",
    "model_save_dir = r\"C:\\Users\\edmun\\Downloads\\forintern\\dataset\\model\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "model_name = \"unet_model.pth\"\n",
    "\n",
    "# Load data\n",
    "test_dataset = dataset()\n",
    "test_dataset.train_images = test_dataset.load_image(image_dir)\n",
    "test_dataset.train_masks = test_dataset.load_image(mask_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35b178-b018-46f1-ba77-fdf00e5dbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.augment_images()\n",
    "\n",
    "image_np = np.stack(test_dataset.aug_images, axis=0).astype(np.float32)\n",
    "mask_np = np.stack(test_dataset.aug_masks, axis=0).astype(np.float32)\n",
    "\n",
    "image_np = np.squeeze(image_np, axis=-1)  # (N, 512, 512)\n",
    "mask_np = np.squeeze(mask_np, axis=-1)\n",
    "\n",
    "image_tensor = torch.tensor(image_np).unsqueeze(1)  # (N, 1, 512, 512)\n",
    "mask_tensor = torch.tensor(mask_np).unsqueeze(1)    # (N, 1, 512, 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfce733-e650-4b61-9a3f-2ee8b82240a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(image_tensor, mask_tensor)\n",
    "val_split = int(len(dataset) * 0.1)\n",
    "train_set, val_set = random_split(dataset, [len(dataset)-val_split, val_split])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc4976-72b0-4189-bbbc-645663d8b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(in_ch=1, out_ch=1).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-6, nesterov=True)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def binary_accuracy(preds, targets, threshold=0.5):\n",
    "    preds = (preds > threshold).float()\n",
    "    correct = (preds == targets).float()\n",
    "    return correct.sum() / correct.numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f3dad-a7e7-45b7-926e-e8c6a2572b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, masks)\n",
    "        acc = binary_accuracy(outputs, masks)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_acc += acc.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Loss: {running_loss/len(train_loader):.4f}  Acc: {running_acc/len(train_loader):.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), os.path.join(model_save_dir, model_name))\n",
    "print(f\"Model saved to: {os.path.join(model_save_dir, model_name)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc59d8ee-c3af-421b-8e12-4f187062927a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
